input {
  kafka {
    bootstrap_servers => "broker:29092"
    topics => "logs"
    codec => "json"
    group_id => "logstashgroup"
  }
}

filter {
   if "nginx" in [tags] {
      grok {
        match => { 
          "message" => [ 
            "%{IPORHOST:remote_ip} - %{DATA:user_name} \[%{HTTPDATE:access_time}\] \"%{WORD:http_method} %{DATA:url} HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code} %{NUMBER:response_time} \"%{DATA:referrer}\" \"%{DATA:agent}\"",
            "%{DATA:access_time} \[%{DATA:level}\] %{NUMBER:error_pid}#%{NUMBER:error_tid}: (\*%{NUMBER:[error_connection_id]} )?%{GREEDYDATA:msg}"
            ]
          }
        overwrite => ["agent"]
      }

      
      mutate {
        add_field => {
            # @timestamp is when filebeat reads the event.
            "read_timestamp" => "%{@timestamp}"
            "source" => "nginx"
        }
      }

      # # msec has millisecond resolution.
      date {
          match => [
              "access_time",
              "UNIX",
              "dd/MMM/YYYY:HH:mm:ss Z",
              "dd/MMM/YYYY HH:mm:ss Z"
          ]
          target => "@timestamp"
      }
      

    # Requires geoip plugin
    if ([remote_ip]) {
      geoip {
          source => "remote_ip"
          target => "geoip"
      }
    }

    # Requires user-agent plugin
    if ([agent]) {
      useragent {
          source => "agent"
          target => "user_agent"
      }
    }

  } 
  else {
      # Docker logs
    mutate {
      add_field => {
        "source" => "%{[container][name]}"
        "log_msg" => "%{[message_json][log]}"
        "read_timestamp" => "%{@timestamp}"
        "access_time" => "%{[message_json][time]}"
      }
    }

    date {
      match => [
        "access_time",
        "yyyy-MM-dd'T'HH:mm:ss.SSSSSSSSS'Z'",
        "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"
      ]
      target=> "@timestamp"
    }

    mutate {
      # removing any color code from log
      gsub => ["log_msg", "\e\[([0-9]{1,2}(;[0-9]{1,2})?)?[m|K]", ""]
    }


    # match server logs or normal logs
    grok {
          match => {
              "log_msg" => [
                "%{IPORHOST:remote_ip} - %{DATA:user_name} \[%{HTTPDATE:time}\] \"%{WORD:http_method} %{DATA:url} HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code} %{NUMBER:response_time} \"%{DATA:referrer}\" \"%{DATA:agent}\"",
                "\[%{DATA:time}\]:%{DATA:user}:%{DATA:level} %{GREEDYDATA:msg}",
                "\[%{DATA:time}\] %{DATA:level} %{GREEDYDATA:msg}"
              ]
          }
      }

    # Requires geoip plugin
    if ([remote_ip]) {
      geoip {
          source => "remote_ip"
          target => "geoip"
      }
    }

    # Requires user-agent plugin
    if ([agent]) {
      useragent {
          source => "agent"
          target => "user_agent"
      }
    }

  }
}


output {
    # server logs contain url
    # normal logs contain level

    # send server logs to server-* index
    if ([url]){
      elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "logstash-server-%{[source]}-%{+YYYY.MM.dd}"
        template_overwrite => false
      }

    } else if ([level]) {

      if [level] in ["error", "info", "debug", "warn", "Error", "Info", "Debug", "Warn", "ERROR", "INFO", "DEBUG", "WARN"] {
        elasticsearch {
          hosts => ["elasticsearch:9200"]
          index => "logstash-logs-%{[source]}-%{+YYYY.MM.dd}"
          template_overwrite => false
        }
      }

    }
  

}